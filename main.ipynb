{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dx3DF9ZNXz0v",
        "outputId": "a5976eb6-5cbf-4a2a-bd5f-fcd13906217c"
      },
      "outputs": [],
      "source": [
        "# !git init .\n",
        "# !git remote add origin https://github.com/kashparty/STP-GSR.git\n",
        "# !git pull origin discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OlwY3TLyY9Uh",
        "outputId": "cdad24b0-0e05-4056-ac52-3f7fa221d2a8"
      },
      "outputs": [],
      "source": [
        "# !pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3-Fold Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "ZM4CkzScXNJk",
        "outputId": "80e2afb2-153a-46b2-cd76-2ceb03a903a9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/vol/bitbucket/akm20/conda/envs/DGLCW2/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/vol/bitbucket/akm20/conda/envs/DGLCW2/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on GPU\n",
            "Training Fold 1/3\n",
            "Model parameters: 317,599\n",
            "STPGSR(\n",
            "  (target_edge_initializer): TargetEdgeInitializer(\n",
            "    (conv1): TransformerConv(160, 67, heads=4)\n",
            "    (bn1): GraphNorm(268)\n",
            "  )\n",
            "  (dual_learner): DualGraphLearner(\n",
            "    (conv1): TransformerConv(3, 1, heads=1)\n",
            "    (bn1): GraphNorm(1)\n",
            "  )\n",
            "  (discriminator): Discriminator(\n",
            "    (dense_1): Dense()\n",
            "    (relu_1): ReLU(inplace=True)\n",
            "    (dense_2): Dense()\n",
            "    (relu_2): ReLU(inplace=True)\n",
            "    (dense_3): Dense()\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 111/111 [05:27<00:00,  2.95s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/60, Generator Loss: 0.18148562526917672, Discriminator Loss: 47.14263756049646\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 111/111 [05:32<00:00,  2.99s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/60, Generator Loss: 0.16111744376453194, Discriminator Loss: 49.664641268618475\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▍         | 5/111 [00:14<05:15,  2.98s/it]"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import hydra\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from hydra import compose, initialize\n",
        "\n",
        "from src.train import train, eval\n",
        "from src.plot_utils import plot_adj_matrices\n",
        "from src.dataset import load_dataset\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def main():\n",
        "    with initialize(version_base=None, config_path=\"configs\"):\n",
        "        config = compose(config_name=\"experiment\")\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"Running on GPU\")\n",
        "    else:\n",
        "        print(\"Running on CPU\")\n",
        "\n",
        "    kf = KFold(n_splits=config.experiment.kfold.n_splits, \n",
        "               shuffle=config.experiment.kfold.shuffle, \n",
        "               random_state=config.experiment.kfold.random_state)\n",
        "\n",
        "    # Initialize folder structure for this run\n",
        "    base_dir = config.experiment.base_dir\n",
        "    model_name = config.model.name\n",
        "    dataset_type = config.dataset.name\n",
        "    run_name = config.experiment.run_name\n",
        "    run_dir = f'{base_dir}/{model_name}/{dataset_type}/{run_name}/'\n",
        "\n",
        "    # Load dataset\n",
        "    source_data, target_data = load_dataset(config)\n",
        "\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(source_data)):\n",
        "        print(f\"Training Fold {fold+1}/3\")\n",
        "\n",
        "        # Initialize results directory\n",
        "        res_dir = f'{run_dir}fold_{fold+1}/'\n",
        "        if not os.path.exists(res_dir):\n",
        "            os.makedirs(res_dir)\n",
        "\n",
        "        # Fetch training and val data for this fold\n",
        "        source_data_train = [source_data[i] for i in train_idx]\n",
        "        target_data_train = [target_data[i] for i in train_idx]\n",
        "        source_data_val = [source_data[i] for i in val_idx]\n",
        "        target_data_val = [target_data[i] for i in val_idx]\n",
        "\n",
        "        # Train model for this fold\n",
        "        train_output = train(config, \n",
        "                              source_data_train, \n",
        "                              target_data_train,\n",
        "                              source_data_val,\n",
        "                              target_data_val, \n",
        "                              res_dir)\n",
        "\n",
        "        # Evaluate model for this fold\n",
        "        eval_output, eval_loss = eval(config, \n",
        "                                      train_output['model'], \n",
        "                                      source_data_val, \n",
        "                                      target_data_val, \n",
        "                                      train_output['criterion_L1'])\n",
        "\n",
        "        # Final evaluation loss for this fold\n",
        "        print(f\"Final Validation Loss (Target): {eval_loss}\")\n",
        "\n",
        "        # Save source, taregt, and eval output for this fold\n",
        "        np.save(f'{res_dir}/eval_output.npy', np.array(eval_output))\n",
        "        np.save(f'{res_dir}/source.npy', np.array([s['mat'] for s in source_data_val]))\n",
        "        np.save(f'{res_dir}/target.npy', np.array([t['mat'] for t in target_data_val]))\n",
        "\n",
        "\n",
        "        # Plot predictions for a random sample\n",
        "        idx = 6\n",
        "        source_mat_test = source_data_val[idx]['mat']\n",
        "        target_mat_test = target_data_val[idx]['mat']\n",
        "        eval_output_t = eval_output[idx]\n",
        "\n",
        "        plot_adj_matrices(source_mat_test, \n",
        "                          target_mat_test, \n",
        "                          eval_output_t, \n",
        "                          idx, \n",
        "                          res_dir, \n",
        "                          file_name=f'eval_sample{idx}')\n",
        "\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluating each fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtpOsCYZYjFR",
        "outputId": "5525d82b-e032-49cb-cb9b-d1932994cdff"
      },
      "outputs": [],
      "source": [
        "from hydra import compose, initialize\n",
        "from src.models.stp_gsr import STPGSR\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "with initialize(version_base=None, config_path=\"configs\"):\n",
        "    config = compose(config_name=\"experiment\")\n",
        "\n",
        "model = STPGSR(config)\n",
        "model.load_state_dict(torch.load(\"results/stp_gsr/train/run4/fold_3/model.pth\", map_location=torch.device(\"cuda\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training final model and running predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWH3waODaOcz"
      },
      "outputs": [],
      "source": [
        "from src.matrix_vectorizer import MatrixVectorizer\n",
        "from src.dataset import create_pyg_graph\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "\n",
        "source_vectorized = np.genfromtxt(\"lr_test.csv\", delimiter=\",\", skip_header=1)\n",
        "source_mat_all = [MatrixVectorizer.anti_vectorize(A, 160) for A in source_vectorized]\n",
        "\n",
        "source_mat_all = [torch.tensor(x, dtype=torch.float) for x in source_mat_all]\n",
        "pyg_partial = partial(create_pyg_graph, node_feature_init=\"adj\", node_feat_dim=160)\n",
        "\n",
        "source_pyg_all = [pyg_partial(x, 160) for x in source_mat_all]\n",
        "source_data = [{'pyg': source_pyg, 'mat': source_mat} for source_pyg, source_mat in zip(source_pyg_all, source_mat_all)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZO80AYpazB9",
        "outputId": "d2b166a0-9c98-40d7-c80e-26745d9a7421"
      },
      "outputs": [],
      "source": [
        "from src.dual_graph_utils import revert_dual\n",
        "\n",
        "model.eval()\n",
        "eval_output = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for source in tqdm(source_data):\n",
        "        source_g = source['pyg']\n",
        "\n",
        "        model_pred, model_target = model(source_g, None)\n",
        "        pred_m = revert_dual(model_pred, 268)    # (n_t, n_t)\n",
        "        pred_m = pred_m.cpu().numpy()\n",
        "        eval_output.append(pred_m)\n",
        "\n",
        "eval_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Submission Generation code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "O_tiSfC2cFqC",
        "outputId": "6915624d-d3a4-4c23-d6b0-38c2e718bdbd"
      },
      "outputs": [],
      "source": [
        "from src.matrix_vectorizer import MatrixVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "test_array = np.concatenate([MatrixVectorizer.vectorize(eo) for eo in eval_output])\n",
        "\n",
        "output_df = pd.DataFrame({\"Predicted\": test_array.flatten()})\n",
        "output_df.index = np.arange(1, len(output_df) + 1)\n",
        "output_df.to_csv(\"submission.csv\", index_label=\"ID\")\n",
        "output_df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "DGLCW2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
